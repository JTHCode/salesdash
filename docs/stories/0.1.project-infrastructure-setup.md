# Story 0.1: Project Infrastructure Setup

## Status
Done

## Story
**As a** project maintainer,
**I want** the project repository scaffolded with required packages, data assets, configuration, and quality tooling,
**so that** Epic 1 feature development can start on a clean, reproducible infrastructure foundation.

## Acceptance Criteria
1. Git repository contains the agreed folder structure (`src/`, `data/`, `tests/`, `.streamlit/`, `requirements.txt`, `README.md`, `.gitignore`) matching the architecture source tree.
2. `data/raw/Sales_dataset.xlsx` (from Kaggle) is stored locally with documentation, and a conversion or loading helper exists so downstream code can access a cleaned CSV or DataFrame without manual steps.
3. `src/app.py` launches a placeholder Streamlit app that loads configuration, initializes caching, and confirms data access without errors.
4. Python dependency management is established via `requirements.txt` and pinned minimum versions for Streamlit, Pandas, NumPy, Plotly, and scikit-learn as defined in the tech stack.
5. Initial quality tooling is in place: project README outlines local setup + Streamlit Cloud deployment steps, and `tests/__init__.py` plus placeholder pytest modules exist to unblock future test additions.

## Tasks / Subtasks
- [x] Initialize repository structure (AC1)
  - [x] Create `src/`, `data/raw/`, `data/processed/`, `tests/`, `.streamlit/`, and housekeeping files per architecture guidance (AC1)
  - [x] Add `.streamlit/config.toml` stub with default theme values (AC1)
- [x] Stage Kaggle dataset and data loader utilities (AC2)
  - [x] Place `Sales_dataset.xlsx` under `data/raw/` and document its origin in README (AC2)
  - [x] Implement `src/data_loader.py` that reads the Excel file, normalizes column names, and returns cached pandas DataFrame (AC2)
  - [x] Optionally emit a cached CSV in `data/processed/` for faster local dev, ensuring regeneration logic is documented (AC2)
- [x] Bootstrap Streamlit application shell (AC3)
  - [x] Implement `src/app.py` with basic page title, data load invocation, and placeholder sections for KPI/time-series/map/forecast (AC3)
  - [x] Configure `st.cache_data` usage in loader to verify caching is operational (AC3)
- [x] Define Python dependencies and tooling (AC4, AC5)
  - [x] Populate `requirements.txt` with minimum versions from tech stack (AC4)
  - [x] Add placeholder pytest modules `tests/test_analytics.py` and `tests/test_forecasting.py` with smoke assertions (AC5)
  - [x] Update README with environment setup, `streamlit run src/app.py`, and Streamlit Community Cloud deployment steps (AC4, AC5)

## Dev Notes
- Architecture source tree reference: see `docs/architecture/source-tree.md` for expected directories and module naming conventions.
- Tech stack requirements: `docs/architecture/tech-stack.md` specifies Python 3.11+, Streamlit 1.29+, Pandas 2.1+, NumPy 1.26+, Plotly 5.18+, scikit-learn 1.4+.
- Dataset: Kaggle Excel located at `sales_data/Sales_dataset.xlsx`; copy into repo at `data/raw/Sales_dataset.xlsx`. Ensure loader handles Excel input and optionally exports a processed CSV for downstream services.
- Streamlit caching: use `st.cache_data` decorators to keep load times under 2 seconds as required by MVP.
- Deployment target: Streamlit Community Cloud. Confirm README notes manual deploy steps and any environment variables (none expected yet).
- Logging & monitoring: for now, add basic `st.write` or `logging` statements indicating successful data load; README should instruct reviewing Streamlit Cloud logs after deployment.

### Testing
- Provide pytest scaffolding under `tests/` so future stories can add assertions. Include a smoke test that validates `data_loader.load_data()` returns a DataFrame with expected columns.
- Document local smoke procedure in README: `streamlit run src/app.py` to ensure placeholder app loads without errors and shows dataset row count.

## Change Log
| Date       | Version | Description                         | Author |
|------------|---------|-------------------------------------|--------|
| 2025-09-30 | v0.1    | Initial draft for infrastructure story | John (PM) |
| 2025-09-30 | v0.2    | Infrastructure scaffold implemented for Story 0.1 | James (Dev) |

## Dev Agent Record

### Agent Model Used
OpenAI GPT-5 (Codex)

### Debug Log References

- Attempted to run pytest; command unavailable on host environment (install pytest to enable automated tests).

### Completion Notes List

- Repository scaffolded with data loaders, Streamlit shell, dependencies, and README to satisfy infrastructure story.
- Kaggle dataset copied to data/raw/ and loader normalises columns while exporting optional CSV.

### File List

- README.md
- requirements.txt
- .streamlit/config.toml
- src/__init__.py
- src/app.py
- src/data_loader.py
- src/components/__init__.py
- src/services/__init__.py
- src/utils/__init__.py
- tests/__init__.py
- tests/test_analytics.py
- tests/test_forecasting.py
- data/raw/Sales_dataset.xlsx
- data/processed/.gitkeep

## QA Results




